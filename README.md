### 简介
这是一个爬虫使用的简易代理服务。如果你需要同时运行多个爬虫，而且你购买的1个或者多个代理供应商的代理，那么你需要一个代理服务收集所有代理，并验证这些代理是否有效，然后通过http接口提供给你的爬虫使用。

此代理服务先收集所有代理，然后验证是否有效，有效则保存在代理池中，并且每隔45秒会重新验证代理池里面全部距离上次验证时间大于45秒的代理，防止爬虫拿到无效的代理。此代理服务使用aiohttp开发，Python3.6以上环境运行。

之所以称之为简易代理服务，是因为返回代理的逻辑很简单，是根据每一个代理的使用次数升序返回给爬虫的，即如果一个代理被使用的次数最少，那么它会被优先拿给爬虫使用。

### 如何使用
1. 仿照 hello_proxy_server/collector/a_sample.py ，编写自己获取代理的逻辑，其中source尤为重要，具有唯一性，将 source 写入 settings.py 中的 PROXY_COLLECTOR_LIST 中，即可收集该类型的代理。
2. 如果需要，可修改 settings.py 中的一些配置，比如监听的端口号等。
2. 运行 `python proxy_server.py` 启动代理服务。

### 接口支持的参数
接口为 http://xxx:xxx/proxy

| 参数名 | 含义 | 默认值 |
| ---- | ---- | ---- |
| https | 是否返回支持https的代理，值为 true 或者 false | false |
| anonymous | 是否返回匿名代理，值为 true 或者 false | true |
| limit | 返回代理的个数，最大值为 20 | 10 |
| format | 返回的代理格式， 值为text（以\r\n为换行符）或者json| text |
